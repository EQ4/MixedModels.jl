{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Fitting Linear Mixed-Effects Models in [Julia](http://julialang.org)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Definition of the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "    \\def\\mc#1{{\\mathcal{#1}}}\n",
      "    \\def\\bm#1{{\\bf #1}}\n",
      "    \\def\\bth{{\\bf\\theta}}\n",
      "    \\def\\bLt{{\\bf\\Lambda_{\\bf\\theta}}}\n",
      "    \\def\\trans{^\\prime}\n",
      "$$\n",
      "A linear mixed-effects model is characterized by the distribution of\n",
      "two vector-valued random variables: the $n$-dimensional response, $\\mc Y$,\n",
      "and the $q$-dimensional random effects vector, $\\mc B$.\n",
      "The unconditional distribution of $\\mc B$ is multivariate normal,\n",
      "$$\n",
      "    \\mc B\\sim \\mc N(\\bm 0,\\bm\\Sigma_{\\bm\\theta}),\n",
      "$$\n",
      "as is the conditional distribution of $\\mc Y$ given $\\mc B=\\bm b$,\n",
      "$$\n",
      "    (\\mc Y|\\mc B=\\bm b)\\sim \\mc N(\\bm X\\bm\\beta+\\bm Z\\bm b, \\sigma^2\\bm I),\n",
      "$$\n",
      "\n",
      "In the [MixedModels](https://github.com/dmbates/MixedModels) package we represent\n",
      "the covariance matrix in the unconditional distribution of $\\mc B$ as\n",
      "$$\n",
      "    \\bm\\Sigma_{\\bm\\theta}=\\sigma^2\\bLt\\bLt\\trans,\n",
      "$$\n",
      "where $\\bLt$ is the $q\\times q$ _relative covariance factor_.\n",
      "We also represent the random variable $\\mc B$ as\n",
      "$$\n",
      "    \\mc B=\\bLt\\mc U\n",
      "$$\n",
      "where $\\mc U$ has a _spherical_ multivariate normal distribution,\n",
      "$$\n",
      "    \\mc U\\sim\\mc N(\\bm 0,\\sigma^2\\bm I).\n",
      "$$\n",
      "This allows us to express the _linear predictor_,\n",
      "$$\n",
      "    \\bm\\mu_{\\mc Y|\\mc B=\\bm b}=\\bm X\\bm\\beta+\\bm Z\\bm b=\\bm X\\bm\\beta+\\bm Z\\bLt\\bm u,\n",
      "$$\n",
      "as a function of $\\bm\\beta$ and $\\bm u$.\n",
      "\n",
      "For given values of $\\bm\\theta$ and $\\bm\\beta$ we solve a penalized linear\n",
      "least squares problem of the form\n",
      "$$\n",
      "    r^2_{\\bth}=\\min_{\\bm\\beta,\\bm u}\\|\\bm y-\\bm X\\bm\\beta-\\bm Z\\bLt\\bm u\\|^2 + \\|\\bm u\\|^2\n",
      "$$\n",
      "for which we compute the _sparse Cholesky factorization_,\n",
      "$$\n",
      "    \\bm L_\\bth\\bm L_\\bth=\\bLt\\trans\\bm Z\\trans \\bm Z\\bLt + \\bm I ,\n",
      "$$\n",
      "where $\\bm L_\\bth$ is a sparse lower-triangular matrix.\n",
      "\n",
      "Because $\\bm L_\\bth$ is triangular, we can easily evaluate its determinant\n",
      "as the product of its diagonal elements.\n",
      "By construction these diagonal elements are positive and the log-determinant, \n",
      "$\\log(|\\bLt\\trans\\bm Z\\trans Z\\bLt+\\bm I|)=2\\log(|\\bm L_\\bth|)$ is easily\n",
      "evaluated.\n",
      "\n",
      "The _profiled_ log-likelihood for a linear mixed-effects model, \n",
      "$\\ell(\\bm\\theta|\\bm y)$, can be expressed as\n",
      "$$\n",
      "    -2\\ell(\\bm\\theta|\\bm y) = \\log(|\\bLt\\trans\\bm Z\\trans\\bm Z\\bLt+\\bm I|)     +n\\left[1+\\log\\left(\\frac{2\\pi r^2_\\bth}{n}\\right)\\right].\n",
      "$$\n",
      "Minimizing this expression with respect to $\\bth$ provides us with the \n",
      "_maximum likelihood estimates_, $\\widehat{\\bth}$, from which we obtain\n",
      "$$\n",
      "   \\widehat{\\sigma^2}=r^2_{\\widehat\\bth}/n.\n",
      "$$\n",
      "The minimizers of the penalized least squares problem at $\\widehat\\bth$\n",
      "are $\\widehat{\\bm\\beta}$ and the _conditional mean_, $\\tilde{\\bm u}$, of $\\mc U$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Expressing the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `lmm` function for fitting linear mixed-effects models uses the formula/data\n",
      "formulation that is familiar to [`R`](http://www.r-project.org) users.\n",
      "The data argument should be a `DataFrame` as defined in the\n",
      "[DataFrames](https://github.com/JuliaStats/DataFrames.jl) package.\n",
      "Several examples of DataFrames are available in the\n",
      "[RDatasets](https://github.com/johnmyleswhite/RDatasets.jl) package.\n",
      "\n",
      "We use David Jones' [Gadfly](https://github.com/dcjones/Gadfly.jl) package in \n",
      "conjunction with [IJulia](https://github.com/JuliaLang/IJulia.jl) for graphics.\n",
      "\n",
      "At present some of these packages produce warnings about ambiguous method definitions\n",
      "when loaded.  To avoid having these warnings clutter the notebook we load them all now\n",
      "and suppress the output from this chunk."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "using RDatasets, MixedModels\n",
      "#using Gadfly            # not happy at present"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now the `DyeStuff` data from the [lme4](https://github.com/lme4/lme4)\n",
      "package for `R` can be loaded and plotted as"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = dataset(\"lme4\",\"Dyestuff\");\n",
      "head(ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"data-frame\"><tr><th></th><th>Batch</th><th>Yield</th></tr><tr><th>1</th><td>A</td><td>1545</td></tr><tr><th>2</th><td>A</td><td>1440</td></tr><tr><th>3</th><td>A</td><td>1440</td></tr><tr><th>4</th><td>A</td><td>1520</td></tr><tr><th>5</th><td>A</td><td>1580</td></tr><tr><th>6</th><td>B</td><td>1540</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "6x2 DataFrame\n",
        "|-------|-------|-------|\n",
        "| Row # | Batch | Yield |\n",
        "| 1     | \"A\"   | 1545  |\n",
        "| 2     | \"A\"   | 1440  |\n",
        "| 3     | \"A\"   | 1440  |\n",
        "| 4     | \"A\"   | 1520  |\n",
        "| 5     | \"A\"   | 1580  |\n",
        "| 6     | \"B\"   | 1540  |"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot(ds, x=\"Yield\", y = \"Batch\", Geom.point)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These data provide the yield of dyestuff in samples taken from different batches of\n",
      "an intermediate product."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A mixed-model formula for `lmm` is similar to those used in `lme4` except that it must\n",
      "be enclosed by `:(` and `)` so that it is parsed as an expression.\n",
      "(In fact, the expression is converted to a `Formula` object but that is not important now.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm1 = fit(lmm(Yield ~ 1 + (1|Batch), ds), true)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: could not import Base.add! into NumericExtensions\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "f_1: 327.76702, [1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".0]\n",
        "f_2: 328.63496, ["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.428326]\n",
        "f_3: 327.33773, [0.787132]\n",
        "f_4: 328.27031, [0.472809]\n",
        "f_5: 327.33282, [0.727955]\n",
        "f_6: 327.32706, [0.752783]\n",
        "f_7: 327.32706, [0.752599]\n",
        "f_8: 327.32706, [0.752355]\n",
        "f_9: 327.32706, [0.752575]\n",
        "f_10: 327.32706, [0.75258]\n",
        "FTOL_REACHED\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Linear mixed model fit by maximum likelihood\n",
        "Formula: Yield ~ 1 + (1 | Batch)\n",
        "\n",
        " logLik: -163.663530, deviance: 327.327060\n",
        "\n",
        " Variance components:\n",
        "                Variance    Std.Dev.\n",
        " Batch        1388.331690   37.260323\n",
        " Residual     2451.250503   49.510105\n",
        " Number of obs: 30; levels of grouping factors: 6\n",
        "\n",
        "  Fixed-effects parameters:\n",
        "             Estimate Std.Error z value\n",
        "(Intercept)    1527.5   17.6945  86.326\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By explicitly calling `fit` on the model object and providing the optional second argument\n",
      "as `true` we get verbose output giving the progress of the optimizer.\n",
      "\n",
      "Common extractors from the object are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show(fixef(fm1)) # estimated fixed-effects parameter vector, beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1527"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".4999999999998]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ranef(fm1) # conditional means of B given Y and parameter estimates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "1-element Array{Any,1}:\n",
        " 1x6 Array{Float64,2}:\n",
        " -16.6282  0.369516  26.9747  -21.8014  53.5798  -42.4943"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ranef(fm1,true) # conditional means on the U scale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1-element Array{Any,1}:\n",
        " 1x6 Array{Float64,2}:\n",
        " -22.0949  0.490999  35.8429  -28.9689  71.1948  -56.4649"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scale(fm1)  # estimated standard deviation of Y given B"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "49.51010506266787"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For models with a single random-effects term the matrix $\\Lambda$ is block diagonal with one block for each level of the random effects grouping factor.  For a single, scalar random effects term the diagonal blocks are repetitions of the $1\\times1$ matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm1.\u03bb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cholesky{Float64} with factor:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Cholesky{Float64} with factor:"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "1-element Array{Any,1}:\n",
        " PDMat(1,1x1 Array{Float64,2}:\n",
        " 0.566377,1x1 Triangular{Float64,Array{Float64,2},:L,false}:\n",
        " 0.75258)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: in the Julia REPL (read-eval-print-loop) characters like $\\lambda$ can be typed using the LaTeX code for the character (e.g. \"\\lambda\") followed by the tab character."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cholfact(fm1,false) # Cholesky factor L"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Cholesky{Float64} with factor:\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "6x6 sparse matrix with 6 Float64 entries:\n",
        "\t[1, 1]  =  1.95752\n",
        "\t[2, 2]  =  1.95752\n",
        "\t[3, 3]  =  1.95752\n",
        "\t[4, 4]  =  1.95752\n",
        "\t[5, 5]  =  1.95752\n",
        "\t[6, 6]  =  1.95752"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm1.\u03bc' # fitted values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "1x30 Array{Float64,2}:\n",
        " 1510.87  1510.87  1510.87  1510.87  \u2026  1485.01  1485.01  1485.01  1485.01"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size(fm1) # no. of obs., fixed-effects parameters, random effects and terms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(30,1,6,1)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "std(fm1)' # estimated standard deviations of variance components"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "1x2 Array{Any,2}:\n",
        " 1x1 Array{Float64,2}:\n",
        " 37.2603  1x1 Array{Float64,2}:\n",
        " 49.5101"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stderr(fm1) # standard errors of the fixed-effects parameter estimates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "1-element Array{Float64,1}:\n",
        " 17.6945"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcov(fm1) # estimated covariance matrix of the estimator of \u03b2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "1x1 Array{Float64,2}:\n",
        " 313.097"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "typeof(fm1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "LinearMixedModel{PLSOne} (constructor with 1 method)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cor(fm1) # estimated correlation matrices per term"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "1-element Array{Any,1}:\n",
        " 1x1 Array{Float64,2}:\n",
        " 1.0"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vector-valued random effects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In some cases we define random effects for both slope and intercept with respect to\n",
      "a covariate.\n",
      "The `sleepstudy` data from the [lme4](https://github.org/lme4/lme4) package provide\n",
      "measurements of reaction time (ms.) for several subjects in a sleep-deprivation\n",
      "experiment.\n",
      "The `Days` covariate is the number of days of sleep deprivation (subjects were allowed\n",
      "only 3 hours for sleeping each night) before the measurement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slp = dataset(\"lme4\",\"sleepstudy\");\n",
      "head(slp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"data-frame\"><tr><th></th><th>Reaction</th><th>Days</th><th>Subject</th></tr><tr><th>1</th><td>249.56</td><td>0</td><td>308</td></tr><tr><th>2</th><td>258.7047</td><td>1</td><td>308</td></tr><tr><th>3</th><td>250.8006</td><td>2</td><td>308</td></tr><tr><th>4</th><td>321.4398</td><td>3</td><td>308</td></tr><tr><th>5</th><td>356.8519</td><td>4</td><td>308</td></tr><tr><th>6</th><td>414.6901</td><td>5</td><td>308</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "6x3 DataFrame\n",
        "|-------|----------|------|---------|\n",
        "| Row # | Reaction | Days | Subject |\n",
        "| 1     | 249.56   | 0    | \"308\"   |\n",
        "| 2     | 258.705  | 1    | \"308\"   |\n",
        "| 3     | 250.801  | 2    | \"308\"   |\n",
        "| 4     | 321.44   | 3    | \"308\"   |\n",
        "| 5     | 356.852  | 4    | \"308\"   |\n",
        "| 6     | 414.69   | 5    | \"308\"   |"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show(slp[:Subject].pool)  # levels of the Subject factor"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ASCIIString"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\"308\",\"309\",\"310\",\"330\",\"331\",\"332\",\"333\",\"334\",\"335\",\"337\",\"349\",\"350\",\"351\",\"352\",\"369\",\"370\",\"371\",\"372\"]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm2 = lmm(Reaction ~ 1 + Days + (1 + Days|Subject), slp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "Linear mixed model fit by maximum likelihood\n",
        "Formula: Reaction ~ 1 + Days + ((1 + Days) | Subject)\n",
        "\n",
        " logLik: -875.969673, deviance: 1751.939345\n",
        "\n",
        " Variance components:\n",
        "                Variance    Std.Dev.  Corr.\n",
        " Subject      565.545224   23.781195\n",
        "               32.692286    5.717717   0.08\n",
        " Residual     654.919662   25.591398\n",
        " Number of obs: 180; levels of grouping factors: 18\n",
        "\n",
        "  Fixed-effects parameters:\n",
        "             Estimate Std.Error z value\n",
        "(Intercept)   251.405   6.63237 37.9058\n",
        "Days          10.4673   1.50242 6.96696\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The within-subject correlation between intercept and slope is estimated but not shown.\n",
      "This will be changed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cor(fm2)  # estimated correlation matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "1-element Array{Any,1}:\n",
        " 2x2 Array{Float64,2}:\n",
        " 1.0        0.0812284\n",
        " 0.0812284  1.0      "
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Models with multiple random-effects terms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `Pastes` and `Penicillin` data from the `lme4` package provide examples\n",
      "of data classified according to two grouping factors.\n",
      "In the case of `Pastes` the grouping factor `sample` is nested within `batch`.\n",
      "In the case of `Penicillin` the grouping factors, `sample` and `plate`, are crossed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psts = dataset(\"lme4\",\"Pastes\")\n",
      "head(psts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"data-frame\"><tr><th></th><th>Strength</th><th>Batch</th><th>Cask</th><th>Sample</th></tr><tr><th>1</th><td>62.8</td><td>A</td><td>a</td><td>A:a</td></tr><tr><th>2</th><td>62.6</td><td>A</td><td>a</td><td>A:a</td></tr><tr><th>3</th><td>60.1</td><td>A</td><td>b</td><td>A:b</td></tr><tr><th>4</th><td>62.3</td><td>A</td><td>b</td><td>A:b</td></tr><tr><th>5</th><td>62.7</td><td>A</td><td>c</td><td>A:c</td></tr><tr><th>6</th><td>63.1</td><td>A</td><td>c</td><td>A:c</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "6x4 DataFrame\n",
        "|-------|----------|-------|------|--------|\n",
        "| Row # | Strength | Batch | Cask | Sample |\n",
        "| 1     | 62.8     | \"A\"   | \"a\"  | \"A:a\"  |\n",
        "| 2     | 62.6     | \"A\"   | \"a\"  | \"A:a\"  |\n",
        "| 3     | 60.1     | \"A\"   | \"b\"  | \"A:b\"  |\n",
        "| 4     | 62.3     | \"A\"   | \"b\"  | \"A:b\"  |\n",
        "| 5     | 62.7     | \"A\"   | \"c\"  | \"A:c\"  |\n",
        "| 6     | 63.1     | \"A\"   | \"c\"  | \"A:c\"  |"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pen = dataset(\"lme4\",\"Penicillin\")\n",
      "head(pen)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"data-frame\"><tr><th></th><th>Diameter</th><th>Plate</th><th>Sample</th></tr><tr><th>1</th><td>27</td><td>a</td><td>A</td></tr><tr><th>2</th><td>23</td><td>a</td><td>B</td></tr><tr><th>3</th><td>26</td><td>a</td><td>C</td></tr><tr><th>4</th><td>23</td><td>a</td><td>D</td></tr><tr><th>5</th><td>23</td><td>a</td><td>E</td></tr><tr><th>6</th><td>21</td><td>a</td><td>F</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "6x3 DataFrame\n",
        "|-------|----------|-------|--------|\n",
        "| Row # | Diameter | Plate | Sample |\n",
        "| 1     | 27       | \"a\"   | \"A\"    |\n",
        "| 2     | 23       | \"a\"   | \"B\"    |\n",
        "| 3     | 26       | \"a\"   | \"C\"    |\n",
        "| 4     | 23       | \"a\"   | \"D\"    |\n",
        "| 5     | 23       | \"a\"   | \"E\"    |\n",
        "| 6     | 21       | \"a\"   | \"F\"    |"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm3 = lmm(Strength ~ 1 + (1|Sample) + (1|Batch), psts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "Linear mixed model fit by maximum likelihood\n",
        "Formula: Strength ~ 1 + (1 | Sample) + (1 | Batch)\n",
        "\n",
        " logLik: -123.997233, deviance: 247.994466\n",
        "\n",
        " Variance components:\n",
        "                Variance    Std.Dev.\n",
        " Sample         8.433471    2.904044\n",
        " Batch          1.198799    1.094897\n",
        " Residual       0.678032    0.823427\n",
        " Number of obs: 60; levels of grouping factors: 30, 10\n",
        "\n",
        "  Fixed-effects parameters:\n",
        "             Estimate Std.Error z value\n",
        "(Intercept)   60.0533  0.642103  93.526\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm4 = lmm(Diameter ~ 1 + (1|Plate) + (1|Sample), pen)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "Linear mixed model fit by maximum likelihood\n",
        "Formula: Diameter ~ 1 + (1 | Plate) + (1 | Sample)\n",
        "\n",
        " logLik: -166.094174, deviance: 332.188349\n",
        "\n",
        " Variance components:\n",
        "                Variance    Std.Dev.\n",
        " Plate          0.714991    0.845571\n",
        " Sample         3.134213    1.770371\n",
        " Residual       0.302430    0.549937\n",
        " Number of obs: 144; levels of grouping factors: 24, 6\n",
        "\n",
        "  Fixed-effects parameters:\n",
        "             Estimate Std.Error z value\n",
        "(Intercept)   22.9722  0.744487 30.8565\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "typeof(fm4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "LinearMixedModel{PLSDiag{Int32}} (constructor with 1 method)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Larger examples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The computational methods in `lme4` and in `MixedModels` have been carefully tuned\n",
      "to provide good performance on relatively large data sets.\n",
      "The `InstEval` data set provides the evaluations by many students, `s`, on many instructors,\n",
      "`d`, over a period of several years."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inst = dataset(\"lme4\",\"InstEval\")\n",
      "head(inst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"data-frame\"><tr><th></th><th>S</th><th>D</th><th>Studage</th><th>Lectage</th><th>Service</th><th>Dept</th><th>Y</th></tr><tr><th>1</th><td>1</td><td>1002</td><td>2</td><td>2</td><td>0</td><td>2</td><td>5</td></tr><tr><th>2</th><td>1</td><td>1050</td><td>2</td><td>1</td><td>1</td><td>6</td><td>2</td></tr><tr><th>3</th><td>1</td><td>1582</td><td>2</td><td>2</td><td>0</td><td>2</td><td>5</td></tr><tr><th>4</th><td>1</td><td>2050</td><td>2</td><td>2</td><td>1</td><td>3</td><td>3</td></tr><tr><th>5</th><td>2</td><td>115</td><td>2</td><td>1</td><td>0</td><td>5</td><td>2</td></tr><tr><th>6</th><td>2</td><td>756</td><td>2</td><td>1</td><td>0</td><td>5</td><td>4</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "6x7 DataFrame\n",
        "|-------|-----|--------|---------|---------|---------|------|---|\n",
        "| Row # | S   | D      | Studage | Lectage | Service | Dept | Y |\n",
        "| 1     | \"1\" | \"1002\" | \"2\"     | \"2\"     | \"0\"     | \"2\"  | 5 |\n",
        "| 2     | \"1\" | \"1050\" | \"2\"     | \"1\"     | \"1\"     | \"6\"  | 2 |\n",
        "| 3     | \"1\" | \"1582\" | \"2\"     | \"2\"     | \"0\"     | \"2\"  | 5 |\n",
        "| 4     | \"1\" | \"2050\" | \"2\"     | \"2\"     | \"1\"     | \"3\"  | 3 |\n",
        "| 5     | \"2\" | \"115\"  | \"2\"     | \"1\"     | \"0\"     | \"5\"  | 2 |\n",
        "| 6     | \"2\" | \"756\"  | \"2\"     | \"1\"     | \"0\"     | \"5\"  | 4 |"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time fm5 = fit(lmm(Y ~ Dept*Service + (1|S) + (1|D), inst))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.522171656 seconds (306309056 bytes allocated, 6.00% gc time)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "Linear mixed model fit by maximum likelihood\n",
        "Formula: Y ~ Dept * Service + (1 | S) + (1 | D)\n",
        "\n",
        " logLik: -118792.776709, deviance: 237585.553417\n",
        "\n",
        " Variance components:\n",
        "                Variance    Std.Dev.\n",
        " S              0.105422    0.324688\n",
        " D              0.258429    0.508359\n",
        " Residual       1.384725    1.176744\n",
        " Number of obs: 73421; levels of grouping factors: 2972, 1128\n",
        "\n",
        "  Fixed-effects parameters:\n",
        "                   Estimate Std.Error   z value\n",
        "(Intercept)         3.22961 0.0640541     50.42\n",
        "Dept5              0.129537  0.101295    1.2788\n",
        "Dept10            -0.176752 0.0881368  -2.00543\n",
        "Dept12            0.0517089 0.0817538  0.632495\n",
        "Dept6             0.0347327 0.0856225  0.405649\n",
        "Dept7              0.145941 0.0998001   1.46233\n",
        "Dept4              0.151689 0.0816911   1.85686\n",
        "Dept8              0.104206  0.118752  0.877503\n",
        "Dept9             0.0440392 0.0963003  0.457312\n",
        "Dept14            0.0517545 0.0986047  0.524868\n",
        "Dept1             0.0466714  0.101944  0.457815\n",
        "Dept3             0.0563455 0.0977943  0.576164\n",
        "Dept11            0.0596525  0.100235  0.595129\n",
        "Dept2            0.00556088  0.110869 0.0501574\n",
        "Service1           0.252024 0.0686508    3.6711\n",
        "Dept5&Service1    -0.180759  0.123179  -1.46744\n",
        "Dept10&Service1   0.0186497  0.110017  0.169517\n",
        "Dept12&Service1   -0.282267 0.0792939  -3.55975\n",
        "Dept6&Service1    -0.494464  0.079028  -6.25682\n",
        "Dept7&Service1    -0.392054  0.110313  -3.55402\n",
        "Dept4&Service1    -0.278546 0.0823729  -3.38152\n",
        "Dept8&Service1    -0.189526   0.11145  -1.70055\n",
        "Dept9&Service1    -0.499867 0.0885425   -5.6455\n",
        "Dept14&Service1   -0.497161 0.0917165  -5.42063\n",
        "Dept1&Service1    -0.240418 0.0982074  -2.44807\n",
        "Dept3&Service1    -0.223013  0.089055  -2.50421\n",
        "Dept11&Service1   -0.516996 0.0809079  -6.38994\n",
        "Dept2&Service1    -0.384769 0.0918433  -4.18941\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another example provided by Martijn Weiling provides \"pronounciation distance from standard Dutch\"\n",
      "on a large selection of words by subjects from different locales."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dialect = DataFrame(read_rda(\"/home/bates/Downloads/dialectNL.rda\")[\"dialectNL\"]);\n",
      "names(dialect)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "37-element Array{Symbol,1}:\n",
        " :Word                                 \n",
        " :Transcriber                          \n",
        " :Location                             \n",
        " :PronDistStdDutch                     \n",
        " :PronDistStdDutch_c                   \n",
        " :Longitude                            \n",
        " :Latitude                             \n",
        " :Geo                                  \n",
        " :WordFreq_log                         \n",
        " :WordFreq_log_z                       \n",
        " :WordCategory                         \n",
        " :WordIsNounOrAdverb                   \n",
        " :WordLength_log                       \n",
        " \u22ee                                     \n",
        " :PopAvgAge_z                          \n",
        " :PopAvgAge_residPopAvgIncome_log_Geo  \n",
        " :PopAvgAge_residPopAvgIncome_log_Geo_z\n",
        " :PopMaleFemaleRatio                   \n",
        " :PopMaleFemaleRatio_z                 \n",
        " :SpeakerIsMale                        \n",
        " :SpeakerBirthYear                     \n",
        " :SpeakerBirthYear_z                   \n",
        " :SpeakerEmploymentLevel               \n",
        " :SpeakerRecordingYear                 \n",
        " :SpeakerRecordingYear_z               \n",
        " :FieldworkerIsMale                    "
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size(dialect)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(225866,37)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time fm6 = fit(lmm(PronDistStdDutch ~ Geo + (1|Word) + (1|Location) + (1|Transcriber),dialect))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13.501525366 seconds (545877700 bytes allocated, 3.34% gc time)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "Linear mixed model fit by maximum likelihood\n",
        "Formula: PronDistStdDutch ~ Geo + (1 | Word) + (1 | Location) + (1 | Transcriber)\n",
        "\n",
        " logLik: 12383.125227, deviance: -24766.250453\n",
        "\n",
        " Variance components:\n",
        "                Variance    Std.Dev.\n",
        " Word           0.023990    0.154887\n",
        " Location       0.002577    0.050764\n",
        " Transcriber    0.000558    0.023621\n",
        " Residual       0.051466    0.226861\n",
        " Number of obs: 225866; levels of grouping factors: 559, 424, 30\n",
        "\n",
        "  Fixed-effects parameters:\n",
        "             Estimate  Std.Error  z value\n",
        "(Intercept)  -4.09797 0.00879846 -465.759\n",
        "Geo           0.97936   0.028718  34.1027\n"
       ]
      }
     ],
     "prompt_number": 31
    }
   ],
   "metadata": {}
  }
 ]
}